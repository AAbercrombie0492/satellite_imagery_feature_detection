{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Anthony Abercrombie 2017-01-28 20:38:54 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.2\n",
      "pandas 0.19.2+0.g825876c.dirty\n",
      "matplotlib 1.5.1\n",
      "Git hash: d54bfb6b9cb90068cdbc52767b48d108e6efdbc0\n"
     ]
    }
   ],
   "source": [
    "# Environment at time of execution\n",
    "%load_ext watermark\n",
    "%pylab inline\n",
    "%watermark -a \"Anthony Abercrombie\" -d -t -v -p numpy,pandas,matplotlib -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import subprocess\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "#File path to get to the project root\n",
    "PROJ_ROOT = os.path.join(os.path.pardir, os.pardir)\n",
    "# add local python functions\n",
    "sys.path.append(os.path.join(PROJ_ROOT, \"src\"))\n",
    "\n",
    "#Load AWS keys as environment variables\n",
    "dotenv_path = os.path.join(PROJ_ROOT, '.env')\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "AWS_ACCESS_KEY = os.environ.get(\"AWS_ACCESS_KEY\")\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "SPARK_HOME = os.environ.get(\"SPARK_HOME\")\n",
    "ec2_keypair = os.environ.get(\"ec2_keypair\")\n",
    "ec2_keypair_pem = os.environ.get(\"ec2_keypair_pem\")\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where is spark-ec2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def spinup_spark_ec2(SPARK_HOME, keypair, keyfile, num_slaves, cluster_name):\n",
    "    bash_command = '{}/bin/spark-ec2 -k {} -i {}> -s {} launch {}'.format(SPARK_HOME, keypair, keyfile, num_slaves, cluster_name)\n",
    "    subprocess.call(export_aws_creds_cmd, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = (SPARK_HOME, ec2_keypair, ec2_keypair_pem, 1, 'spark_ec2_cluster')\n",
    "x = spinup_spark_ec2(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7/\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/beeline\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/beeline.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/find-spark-home\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/load-spark-env.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/load-spark-env.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/pyspark\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/pyspark.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/pyspark2.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/run-example\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/run-example.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-class\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-class.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-class2.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-shell\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-shell.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-shell2.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-submit\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-submit.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/spark-submit2.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/sparkR\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/sparkR.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//bin/sparkR2.cmd\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/docker.properties.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/fairscheduler.xml.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/log4j.properties.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/metrics.properties.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/slaves.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/spark-defaults.conf.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//conf/spark-env.sh.template\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/graphx\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/graphx/followers.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/graphx/users.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/als\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/als/sample_movielens_ratings.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/als/test.data\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/gmm_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/kmeans_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/pagerank_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/pic_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/ridge-data\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/ridge-data/lpsa.data\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_binary_classification_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_fpgrowth.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_isotonic_regression_libsvm_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_kmeans_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_lda_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_lda_libsvm_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_libsvm_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_linear_regression_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_movielens_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_multiclass_classification_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/sample_svm_data.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/mllib/streaming_kmeans_data_test.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//data/streaming/AFINN-111.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//derby.log\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/jars\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/jars/scopt_2.11-3.3.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/jars/spark-examples_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaTC.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\r",
      "\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/hive\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaFlumeEventCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaKafkaWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/als.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/avro_inputformat.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/kmeans.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/logistic_regression.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/aft_survival_regression.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/als_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/binarizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/bisecting_k_means_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/bucketizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/chisq_selector_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/count_vectorizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/cross_validator.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/dataframe_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/dct_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/decision_tree_classification_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/decision_tree_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/elementwise_product_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/estimator_transformer_param_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/gaussian_mixture_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/generalized_linear_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/index_to_string_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/isotonic_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/kmeans_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/lda_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/linear_regression_with_elastic_net.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/logistic_regression_summary_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/logistic_regression_with_elastic_net.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/max_abs_scaler_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/min_max_scaler_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/multilayer_perceptron_classification.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/n_gram_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/naive_bayes_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/normalizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/one_vs_rest_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/onehot_encoder_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/pca_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/pipeline_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/polynomial_expansion_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/quantile_discretizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/random_forest_classifier_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/random_forest_regressor_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/rformula_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/sql_transformer.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/standard_scaler_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/stopwords_remover_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/string_indexer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/tf_idf_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/tokenizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/train_validation_split.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/vector_assembler_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/vector_indexer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/vector_slicer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/ml/word2vec_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/binary_classification_metrics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/bisecting_k_means_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/correlations.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/correlations_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/decision_tree_classification_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/decision_tree_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/elementwise_product_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/fpgrowth_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/gaussian_mixture_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/gaussian_mixture_model.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/gradient_boosting_classification_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/gradient_boosting_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/hypothesis_testing_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/isotonic_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/k_means_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/kernel_density_estimation_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/kmeans.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/linear_regression_with_sgd_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/logistic_regression.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/multi_class_metrics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/multi_label_metrics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/naive_bayes_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/normalizer_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/power_iteration_clustering_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/random_forest_classification_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/random_forest_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/random_rdd_generation.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/ranking_metrics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/recommendation_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/regression_metrics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/sampled_rdds.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/standard_scaler_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/stratified_sampling_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/streaming_k_means_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/streaming_linear_regression_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/summary_statistics_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/svm_with_sgd_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/tf_idf_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/word2vec.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/mllib/word2vec_example.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/pagerank.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/parquet_inputformat.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/pi.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sort.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/basic.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/datasource.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/hive.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/streaming/structured_network_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/status_api_demo.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/direct_kafka_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/flume_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/hdfs_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/kafka_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/network_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/network_wordjoinsentiments.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/queue_stream.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/recoverable_network_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/sql_network_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/streaming/stateful_network_wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/transitive_closure.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/python/wordcount.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/data-manipulation.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/dataframe.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/als.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/gaussianMixture.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/gbt.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/glm.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/isoreg.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/kmeans.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/kstest.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/lda.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/logit.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/ml.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/mlp.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/naiveBayes.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/randomForest.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/ml/survreg.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/r/RSparkSQLExample.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/full_user.avsc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/kv1.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/people.json\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/people.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/user.avsc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/users.avro\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/resources/users.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/pythonconverters\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/hive\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/clickstream\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/FlumeEventCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/FlumePollingEventCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/KafkaWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/activation-1.1.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/antlr-2.7.7.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/antlr-runtime-3.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/antlr4-runtime-4.5.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/aopalliance-1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/aopalliance-repackaged-2.4.0-b34.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/apache-log4j-extras-1.2.17.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/apacheds-i18n-2.0.0-M15.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/apacheds-kerberos-codec-2.0.0-M15.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/api-asn1-api-1.0.0-M20.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/api-util-1.0.0-M20.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/arpack_combined_all-0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/avro-1.7.7.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/avro-ipc-1.7.7.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/avro-mapred-1.7.7-hadoop2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/base64-2.3.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/bcprov-jdk15on-1.51.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/bonecp-0.8.0.RELEASE.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/breeze-macros_2.11-0.12.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/breeze_2.11-0.12.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/calcite-avatica-1.2.0-incubating.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/calcite-core-1.2.0-incubating.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/calcite-linq4j-1.2.0-incubating.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/chill-java-0.8.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/chill_2.11-0.8.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-beanutils-1.7.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-beanutils-core-1.8.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-cli-1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-codec-1.10.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-collections-3.2.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-compiler-3.0.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-compress-1.4.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-configuration-1.6.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-crypto-1.0.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-dbcp-1.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-digester-1.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-httpclient-3.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-io-2.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-lang-2.6.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-lang3-3.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-logging-1.1.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-math3-3.4.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-net-2.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/commons-pool-1.5.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/compress-lzf-1.0.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/core-1.1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/curator-client-2.6.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/curator-framework-2.6.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/curator-recipes-2.6.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/datanucleus-api-jdo-3.2.6.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/datanucleus-core-3.2.10.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/datanucleus-rdbms-3.2.9.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/derby-10.12.1.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/eigenbase-properties-1.1.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/gson-2.2.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/guava-14.0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/guice-3.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/guice-servlet-3.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-annotations-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-auth-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-client-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-common-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-hdfs-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-mapreduce-client-app-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-mapreduce-client-common-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-mapreduce-client-core-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-yarn-api-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-yarn-client-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-yarn-common-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-yarn-server-common-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hadoop-yarn-server-web-proxy-2.7.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hive-beeline-1.2.1.spark2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hive-cli-1.2.1.spark2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hive-exec-1.2.1.spark2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hive-jdbc-1.2.1.spark2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hive-metastore-1.2.1.spark2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hk2-api-2.4.0-b34.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hk2-locator-2.4.0-b34.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/hk2-utils-2.4.0-b34.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/htrace-core-3.1.0-incubating.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/httpclient-4.5.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/httpcore-4.4.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/ivy-2.4.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-annotations-2.6.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-core-2.6.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-core-asl-1.9.13.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-databind-2.6.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-jaxrs-1.9.13.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-mapper-asl-1.9.13.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-module-paranamer-2.6.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-module-scala_2.11-2.6.5.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jackson-xc-1.9.13.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/janino-3.0.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/java-xmlbuilder-1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/JavaEWAH-0.3.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javassist-3.18.1-GA.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javax.annotation-api-1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javax.inject-1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javax.inject-2.4.0-b34.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javax.servlet-api-3.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javax.ws.rs-api-2.0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/javolution-5.5.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jaxb-api-2.2.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jcl-over-slf4j-1.7.16.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jdo-api-3.0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-client-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-common-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-container-servlet-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-container-servlet-core-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-guava-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-media-jaxb-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jersey-server-2.22.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jets3t-0.9.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jetty-6.1.26.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jetty-util-6.1.26.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jline-2.12.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/joda-time-2.9.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jodd-core-3.5.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jpam-1.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/json4s-ast_2.11-3.2.11.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/json4s-core_2.11-3.2.11.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/json4s-jackson_2.11-3.2.11.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jsp-api-2.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jsr305-1.3.9.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jta-1.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jtransforms-2.4.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/jul-to-slf4j-1.7.16.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/kryo-shaded-3.0.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/leveldbjni-all-1.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/libfb303-0.9.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/libthrift-0.9.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/log4j-1.2.17.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/lz4-1.3.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/mail-1.4.7.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/mesos-1.0.0-shaded-protobuf.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/metrics-core-3.1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/metrics-graphite-3.1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/metrics-json-3.1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/metrics-jvm-3.1.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/minlog-1.3.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/mx4j-3.0.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/netty-3.8.0.Final.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/netty-all-4.0.42.Final.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/objenesis-2.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/opencsv-2.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/oro-2.0.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/osgi-resource-locator-1.0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/paranamer-2.3.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-column-1.8.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-common-1.8.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-encoding-1.8.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-format-2.3.0-incubating.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-hadoop-1.8.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-hadoop-bundle-1.6.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/parquet-jackson-1.8.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/pmml-model-1.2.15.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/pmml-schema-1.2.15.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/protobuf-java-2.5.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/py4j-0.10.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/pyrolite-4.13.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/RoaringBitmap-0.5.11.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scala-compiler-2.11.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scala-library-2.11.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scala-parser-combinators_2.11-1.0.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scala-reflect-2.11.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scala-xml_2.11-1.0.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/scalap-2.11.8.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/shapeless_2.11-2.0.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/slf4j-api-1.7.16.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/slf4j-log4j12-1.7.16.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/snappy-0.2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/snappy-java-1.1.2.6.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-catalyst_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-core_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-graphx_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-hive-thriftserver_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-hive_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-launcher_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-mesos_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-mllib-local_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-mllib_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-network-common_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-network-shuffle_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-repl_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-sketch_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-sql_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-streaming_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-tags_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-unsafe_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spark-yarn_2.11-2.1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spire-macros_2.11-0.7.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/spire_2.11-0.7.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/ST4-4.0.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/stax-api-1.0-2.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/stax-api-1.0.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/stream-2.7.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/stringtemplate-3.2.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/super-csv-2.2.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/univocity-parsers-2.2.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/validation-api-1.1.0.Final.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/xbean-asm5-shaded-4.4.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/xercesImpl-2.9.1.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/xmlenc-0.52.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/xz-1.0.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//jars/zookeeper-3.4.6.jar\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//LICENSE\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-AnchorJS.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-antlr.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-boto.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-cloudpickle.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-d3.min.js.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-dagre-d3.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-DPark.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-f2j.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-graphlib-dot.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-heapq.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-javolution.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-jbcrypt.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-jline.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-jpmml-model.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-jquery.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-junit-interface.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-kryo.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-minlog.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-Mockito.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-modernizr.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-netlib.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-paranamer.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-postgresql.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-protobuf.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-py4j.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-pyrolite.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-reflectasm.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-sbt-launch-lib.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-scala.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-scalacheck.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-scopt.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-slf4j.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-SnapTree.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-sorttable.js.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-spire.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//licenses/LICENSE-xmlenc.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/db.lck\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/dbex.lck\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/log\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/log/log.ctrl\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/log/log1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/log/logmirror.ctrl\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/log/README_DO_NOT_TOUCH_FILES.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/README_DO_NOT_TOUCH_FILES.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c10.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c101.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c111.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c121.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c130.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c141.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c150.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c161.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c171.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c180.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c191.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1c0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1e0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c1f1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c20.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c200.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c211.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c221.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c230.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c241.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c251.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c260.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c271.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c281.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c290.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2d0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c2f0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c300.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c31.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c311.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c321.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c331.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c340.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c351.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c361.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c371.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c380.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c391.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3c0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c3f1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c400.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c41.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c411.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c421.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c430.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c441.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c451.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c461.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c470.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c481.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c490.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4b0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c4f0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c501.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c51.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c510.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c521.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c530.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c541.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c550.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c561.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c570.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c581.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c590.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5b0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5d0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c5f0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c60.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c601.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c610.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c621.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c630.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c641.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c650.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c661.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c670.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c681.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c690.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6b0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6d0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c6f0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c701.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c71.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c711.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c721.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c731.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c741.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c751.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c761.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c771.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c781.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c791.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c7f1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c801.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c81.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c811.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c821.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c831.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c840.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c851.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c860.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c871.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c880.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c891.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8a0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8c1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8e1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c8f1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c90.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c901.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c911.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c920.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c931.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c940.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c951.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c960.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c971.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c981.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c990.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9a1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9b1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9c0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9d1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9e0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/c9f1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/ca01.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/ca1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/ca11.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/ca21.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/cb1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/cc0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/cd1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/ce1.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/cf0.dat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/seg0/README_DO_NOT_TOUCH_FILES.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/service.properties\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//metastore_db/tmp\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//NOTICE\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/dependency_links.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/not-zip-safe\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/PKG-INFO\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/requires.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/SOURCES.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/EGG-INFO/top_level.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/__init__.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/pandoc_download.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/pandoc_download.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/py3compat.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/pypandoc-1.3.3-py2.7.egg/pypandoc/py3compat.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.eggs/README.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/.gitignore\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/dist\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/_static\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/_static/pyspark.css\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/_static/pyspark.js\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/_templates\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/_templates/layout.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/conf.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/epytext.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/index.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/make.bat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/make2.bat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/Makefile\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/pyspark.ml.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/pyspark.mllib.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/pyspark.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/pyspark.sql.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/docs/pyspark.streaming.rst\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/lib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/lib/py4j-0.10.4-src.zip\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/lib/PY4J_LICENSE.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/lib/pyspark.zip\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/MANIFEST.in\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pylintrc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/__init__.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/accumulators.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/broadcast.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/cloudpickle.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/conf.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/context.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/files.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/find_spark_home.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/heapq3.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/java_gateway.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/join.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/profiler.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/rdd.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/rddsampler.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/resultiterable.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/serializers.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/shuffle.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/statcounter.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/status.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/storagelevel.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/traceback_utils.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/__pycache__/version.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/accumulators.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/broadcast.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/cloudpickle.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/conf.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/context.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/daemon.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/files.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/find_spark_home.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/heapq3.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/java_gateway.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/join.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/base.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/classification.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/clustering.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/common.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/evaluation.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/feature.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/linalg\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/linalg/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/param\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/param/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/param/_shared_params_code_gen.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/param/shared.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/pipeline.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/recommendation.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/regression.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/tuning.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/util.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/ml/wrapper.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/classification.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/clustering.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/common.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/evaluation.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/feature.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/fpm.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/linalg\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/linalg/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/linalg/distributed.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/random.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/recommendation.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/regression.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat/_statistics.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat/distribution.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat/KernelDensity.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/stat/test.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/tree.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/mllib/util.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/profiler.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/python\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/python/pyspark\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/python/pyspark/shell.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/rdd.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/rddsampler.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/resultiterable.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/serializers.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/shell.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/shuffle.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/__init__.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/catalog.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/column.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/conf.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/context.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/dataframe.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/functions.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/group.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/readwriter.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/session.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/streaming.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/types.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/utils.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/__pycache__/window.cpython-35.pyc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/catalog.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/column.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/conf.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/context.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/dataframe.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/functions.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/group.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/readwriter.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/session.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/streaming.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/types.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/utils.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/sql/window.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/statcounter.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/status.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/storagelevel.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/__init__.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/context.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/dstream.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/flume.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/kafka.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/kinesis.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/listener.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/streaming/util.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/traceback_utils.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/version.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark/worker.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info/dependency_links.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info/PKG-INFO\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info/requires.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info/SOURCES.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/pyspark.egg-info/top_level.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/README.md\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/run-tests\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/run-tests.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/setup.cfg\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/setup.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/hello\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/hello/hello.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/hello/sub_hello\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/hello/sub_hello/sub_hello.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/SimpleHTTPServer.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/ages.csv\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/_SUCCESS\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=0\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=0/c=0\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=1\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=1/c=1\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/_common_metadata\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/_metadata\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/_SUCCESS\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2014\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2014/month=9\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=9\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/people.json\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/people1.json\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/streaming\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/streaming/text-test.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/sql/text-test.txt\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/userlib-0.1.zip\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//python/test_support/userlibrary.py\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/DESCRIPTION\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help/aliases.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help/AnIndex\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help/paths.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help/SparkR.rdb\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/help/SparkR.rdx\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/00Index.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/abs.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/acos.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/add_months.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/AFTSurvivalRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/alias.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ALSModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/approxCountDistinct.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/approxQuantile.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/arrange.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/array_contains.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/as.data.frame.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ascii.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/asin.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/atan.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/atan2.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/attach.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/avg.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/base64.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/between.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/bin.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/bitwiseNOT.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/bround.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cache.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cacheTable.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cancelJobGroup.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cast.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cbrt.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ceil.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/clearCache.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/clearJobGroup.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/collect.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/coltypes.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/column.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/columnfunctions.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/columns.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/concat.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/concat_ws.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/conv.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/corr.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cos.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cosh.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/count.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/countDistinct.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cov.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/covar_pop.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/crc32.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/createDataFrame.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/createExternalTable.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/createOrReplaceTempView.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/crossJoin.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/crosstab.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/cume_dist.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dapply.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dapplyCollect.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/date_add.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/date_format.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/date_sub.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/datediff.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dayofmonth.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dayofyear.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/decode.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dense_rank.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dim.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/distinct.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/drop.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dropDuplicates.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dropTempTable-deprecated.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dropTempView.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/dtypes.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/encode.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/endsWith.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/except.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/exp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/explain.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/explode.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/expm1.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/expr.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/factorial.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/filter.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/first.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/fitted.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/floor.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/format_number.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/format_string.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/freqItems.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/from_unixtime.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/from_utc_timestamp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/gapply.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/gapplyCollect.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/GaussianMixtureModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/GBTClassificationModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/GBTRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/GeneralizedLinearRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/generateAliasesForIntersectedCols.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/glm.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/greatest.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/groupBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/GroupedData.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/hash.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/hashCode.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/head.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/hex.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/histogram.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/hour.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/hypot.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ifelse.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/initcap.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/insertInto.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/install.spark.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/instr.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/intersect.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/is.nan.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/isLocal.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/IsotonicRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/join.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/KMeansModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/KSTest-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/kurtosis.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/lag.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/last.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/last_day.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/LDAModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/lead.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/least.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/length.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/levenshtein.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/limit.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/lit.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/locate.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/log.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/log10.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/log1p.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/log2.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/LogisticRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/lower.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/lpad.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ltrim.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/match.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/max.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/md5.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/mean.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/merge.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/min.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/minute.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/monotonically_increasing_id.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/month.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/months_between.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/MultilayerPerceptronClassificationModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/mutate.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/nafunctions.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/NaiveBayesModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/nanvl.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ncol.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/negate.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/next_day.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/nrow.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/ntile.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/orderBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/otherwise.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/over.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/partitionBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/percent_rank.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/persist.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/pivot.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/pmod.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/posexplode.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/predict.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/print.jobj.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/print.structField.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/print.structType.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/printSchema.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/quarter.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/R.css\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rand.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/randn.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/RandomForestClassificationModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/RandomForestRegressionModel-class.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/randomSplit.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rangeBetween.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rank.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rbind.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.df.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.jdbc.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.json.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.ml.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.orc.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.parquet.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/read.text.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/regexp_extract.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/regexp_replace.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/registerTempTable-deprecated.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rename.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/repartition.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/reverse.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rint.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/round.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/row_number.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rowsBetween.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rpad.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/rtrim.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sample.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sampleBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/saveAsTable.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/schema.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sd.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/second.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/select.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/selectExpr.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/setJobGroup.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/setLogLevel.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sha1.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sha2.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/shiftLeft.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/shiftRight.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/shiftRightUnsigned.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/show.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/showDF.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sign.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sin.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sinh.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/size.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/skewness.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sort_array.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/soundex.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.addFile.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.als.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.gaussianMixture.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.gbt.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.getSparkFiles.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.getSparkFilesRootDirectory.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.glm.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.isoreg.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.kmeans.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.kstest.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.lapply.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.lda.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.logit.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.mlp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.naiveBayes.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.randomForest.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark.survreg.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/spark_partition_id.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/SparkDataFrame.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.callJMethod.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.callJStatic.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.conf.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.init-deprecated.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.newJObject.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.session.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.session.stop.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkR.version.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkRHive.init-deprecated.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sparkRSQL.init-deprecated.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sql.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sqrt.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/startsWith.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/stddev_pop.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/stddev_samp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/storageLevel.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/str.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/struct.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/structField.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/structType.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/subset.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/substr.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/substring_index.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sum.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/sumDistinct.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/summarize.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/summary.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/tableNames.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/tables.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/tableToDF.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/take.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/tan.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/tanh.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/to_date.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/to_utc_timestamp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/toDegrees.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/toRadians.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/translate.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/trim.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/unbase64.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/uncacheTable.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/unhex.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/union.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/unix_timestamp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/unpersist.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/upper.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/var.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/var_pop.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/var_samp.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/weekofyear.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/when.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/window.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/windowOrderBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/windowPartitionBy.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/WindowSpec.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/with.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/withColumn.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.df.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.jdbc.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.json.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.ml.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.orc.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.parquet.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/write.text.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/html/year.html\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/INDEX\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta/hsearch.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta/links.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta/nsInfo.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta/package.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/Meta/Rd.rds\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/NAMESPACE\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/profile\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/profile/general.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/profile/shell.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/R/SparkR\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/R/SparkR.rdb\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/R/SparkR.rdx\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/jarTest.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/packageInAJarTest.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_binary_function.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_binaryFile.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_broadcast.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_client.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_context.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_includePackage.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_jvm_api.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_mllib.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_parallelize_collect.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_rdd.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_Serde.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_shuffle.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_sparkR.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_sparkSQL.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_take.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_textFile.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_utils.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/tests/testthat/test_Windows.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/worker\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/worker/daemon.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/SparkR/worker/worker.R\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//R/lib/sparkr.zip\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//README.md\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//RELEASE\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/slaves.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/spark-config.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/spark-daemon.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/spark-daemons.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-all.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-history-server.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-master.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-mesos-dispatcher.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-mesos-shuffle-service.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-shuffle-service.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-slave.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-slaves.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/start-thriftserver.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-all.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-history-server.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-master.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-mesos-dispatcher.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-mesos-shuffle-service.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-shuffle-service.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-slave.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-slaves.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//sbin/stop-thriftserver.sh\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//yarn\r\n",
      "/Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7//yarn/spark-2.1.0-yarn-shuffle.jar\r\n",
      "find: ec2: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!find /Users/AnthonyAbercrombie/spark-2.1.0-bin-hadoop2.7/ ec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/spark-2.1.0-bin-hadoop2.7/bin/spark-ec2 -k aws-key-fast-ai -i ~/.ssh/aws-key-fast-ai.pem> -s 1 launch spark_ec2_cluster'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'{}/bin/spark-ec2 -k {}<keypair> -i {}<key-file> -s {}<num-slaves> launch {}<cluster-name>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical DataFlow with Spark and Tensorflow\n",
    "#### checkout tensorframes from databricks\n",
    "\n",
    "```python\n",
    "df = sqlContext.createDataFrame()\n",
    "x= tf.placeholder(tf.int32, name='x')\n",
    "y= tf.placeholder(tf.int32, name='y')\n",
    "output = tf.add(x, 3*y, name='z')\n",
    "\n",
    "\n",
    "session = tf.session()\n",
    "output_value = session.run(output, {x:3, y:5})\n",
    "\n",
    "output_df = tfs.map_rows(output, df)\n",
    "output_df.collect()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
